{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第５章　実習１\n",
    "## 問題１\n",
    "### ▶ テキスト P84  ５．３ 学習ステップを確認するのリストにおいて、勾配降下法による学習処理、学習結果を表示する処理を関数にしてください。また、関数化に伴ってスカラー積を求める関数を改良してください。下記の実行結果になるように、コメントに従ってプログラムを実装してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 回目学習\n",
      "予測値 = 0.8600\n",
      "重みリスト = [0.111900, 0.200910, -0.098320]\n",
      "2 回目学習\n",
      "予測値 = 0.9638\n",
      "重みリスト = [0.114981, 0.201146, -0.097885]\n",
      "3 回目学習\n",
      "予測値 = 0.9906\n",
      "重みリスト = [0.115778, 0.201207, -0.097773]\n"
     ]
    }
   ],
   "source": [
    "# 予測する関数 neural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    # 予測値を初期化\n",
    "    out = 0\n",
    "    # 入力層ニューロンの数分繰り返す\n",
    "    for i in range(len(input)):\n",
    "        # 予測値（＝加重和＝内積値）を求める\n",
    "        out += (input[i] * weights[i])\n",
    "    # 予測値を返す\n",
    "    return out\n",
    "\n",
    "# スカラー積を求める関数 ele_mul の定義\n",
    "def ele_mul(scalar, vector):\n",
    "    # スカラー積の結果を返すリストの初期化\n",
    "   out = [0, 0, 0]\n",
    "    # ベクトルの長さ分繰り返す\n",
    "    for i in range(len(out)):\n",
    "        # スカラー積を求めて、リストに追加する\n",
    "        out.append(vector[i] * scalar)\n",
    "    # スカラー積を返す\n",
    "    return out\n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値リスト\n",
    "    truth：目的値\n",
    "    pred：予測値\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "def grad_descent_learn(input, truth, pred, weights, alpha):\n",
    "    delta = pred - goal_pred\n",
    "    weight = input * delta\n",
    "    return weight\n",
    "    # 誤差を求める\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    # デルタを求める\n",
    "    delta = pred - truth\n",
    "    # 重みの微調整量を求める\n",
    "    weights_delta = ele_mul(delta, input)\n",
    "    # 重みを修正する\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weights_delta[i]\n",
    "    # 更新した重みリストを返す\n",
    "    return weights\n",
    "\n",
    "# 学習結果を表示する関数 disp_learn の定義\n",
    "'''\n",
    "関数名：disp_learn\n",
    "引数：iter = 学習回数、pred = 予測値、weights = 重みリスト\n",
    "処理：学習回数、予測値（小数点以下４桁）、重みを表示する（小数点以下６桁）\n",
    "戻り値：なし\n",
    "'''\n",
    "def disp_learn(iter, pred, weights):\n",
    "    # 学習回数を表示\n",
    "    \n",
    "    # 予測値を表示\n",
    "    \n",
    "    # 重みリストを表示\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 入力データセット\n",
    "# シーズンの各選手の足指の平均数を初期化\n",
    "toes =  [8.5, 9.5, 9.9, 9.0]\n",
    "# シーズンの勝率を初期化\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "# シーズンのファンの数（百万単位）を初期化\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "# シーズン４試合の勝ち負けを初期化\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "# シーズン第１試合の結果初期化\n",
    "truth = win_or_lose_binary[0]\n",
    "\n",
    "# アルファを初期化\n",
    "alpha = 0.01\n",
    "# 入力層から出力層への重みの初期化\n",
    "weights = [0.1, 0.2, -0.1]\n",
    "# 入力はシーズン最初の試合の３つのデータポイントを設定\n",
    "input = []\n",
    "\n",
    "# ３回学習する\n",
    "\n",
    "    # 予測する\n",
    "    \n",
    "    # 学習＝重みを修正\n",
    "    \n",
    "    # 学習結果を表示\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1回目の学習\n予測値 = 0.8600000000000001\n重みリスト = [0.1119, 0.20091, -0.09832]\n2回目の学習\n予測値 = 0.9637574999999999\n重みリスト = [0.11498061250000001, 0.20114557625, -0.09788509000000001]\n3回目の学習\n予測値 = 0.9906177228125002\n重みリスト = [0.1157781060609375, 0.20120656105171877, -0.09777250267375001]\n"
     ]
    }
   ],
   "source": [
    "# 予測する関数 neural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    # 予測値を初期化\n",
    "    out = 0\n",
    "    # 入力層ニューロンの数分繰り返す\n",
    "    for i in range(len(input)):\n",
    "        # 予測値（＝加重和＝内積値）を求める\n",
    "        out += (input[i] * weights[i])\n",
    "    # 予測値を返す\n",
    "    return out\n",
    "\n",
    "# スカラー積を求める関数 ele_mul の定義\n",
    "def ele_mul(scalar, vector):\n",
    "    # スカラー積の結果を返すリストの初期化\n",
    "    out = []\n",
    "    # ベクトルの長さ分繰り返す\n",
    "    for i in range(len(input)):\n",
    "        # スカラー積を求めて、リストに追加する\n",
    "        out.append(vector[i] * scalar)\n",
    "    # スカラー積を返す\n",
    "    return out\n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値リスト\n",
    "    truth：目的値\n",
    "    pred：予測値\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "def grad_descent_learn(input, truth, pred, weights, alpha):\n",
    "    # 誤差を求める\n",
    "    error = (pred - truth) ** 2\n",
    "    # デルタを求める\n",
    "    delta = pred - truth\n",
    "    # 重みの微調整量を求める\n",
    "    weights_deltas = ele_mul(delta, input)\n",
    "    # 重みを修正する\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weights_deltas[i]\n",
    "    # 更新した重みリストを返す\n",
    "    return weights\n",
    "\n",
    "# 学習結果を表示する関数 disp_learn の定義\n",
    "'''\n",
    "関数名：disp_learn\n",
    "引数：iter = 学習回数、pred = 予測値、weights = 重みリスト\n",
    "処理：学習回数、予測値（小数点以下４桁）、重みを表示する（小数点以下６桁）\n",
    "戻り値：なし\n",
    "'''\n",
    "def disp_learn(iter, pred, weights):\n",
    "    # 学習回数を表示\n",
    "    print(str(iter+1) + \"回目の学習\")\n",
    "    # 予測値を表示\n",
    "    print(\"予測値 = \" + str(pred))\n",
    "    # 重みリストを表示\n",
    "    print(\"重みリスト = \" + str(weights))\n",
    "\n",
    "\n",
    "# 入力データセット\n",
    "# シーズンの各選手の足指の平均数を初期化\n",
    "toes =  [8.5, 9.5, 9.9, 9.0]\n",
    "# シーズンの勝率を初期化\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "# シーズンのファンの数（百万単位）を初期化\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "# シーズン４試合の勝ち負けを初期化\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "# シーズン第１試合の結果初期化\n",
    "truth = win_or_lose_binary[0]\n",
    "\n",
    "# アルファを初期化\n",
    "alpha = 0.01\n",
    "# 入力層から出力層への重みの初期化\n",
    "weights = [0.1, 0.2, -0.1]\n",
    "# 入力はシーズン最初の試合の３つのデータポイントを設定\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "\n",
    "# ３回学習する\n",
    "for iter in range(3):\n",
    "    # 予測する\n",
    "    pred = neural_network(input, weights)\n",
    "    # 学習＝重みを修正\n",
    "    weights = grad_descent_learn(input, truth, pred, weights, alpha)\n",
    "    # 学習結果を表示\n",
    "    disp_learn(iter, pred, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題２\n",
    "### ▶ 問題１のプログラムにおいて、シーズン全試合の学習結果を表示するようにコメントに従ってプログラムを実装してください。実行結果は下記のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "シーズン　第1試合\n",
      "1 回目学習\n",
      "予測値 = 0.8600\n",
      "重みリスト = [0.111900, 0.200910, -0.098320]\n",
      "2 回目学習\n",
      "予測値 = 0.9638\n",
      "重みリスト = [0.114981, 0.201146, -0.097885]\n",
      "3 回目学習\n",
      "予測値 = 0.9906\n",
      "重みリスト = [0.115778, 0.201207, -0.097773]\n",
      "\n",
      "シーズン　第2試合\n",
      "1 回目学習\n",
      "予測値 = 1.1338\n",
      "重みリスト = [0.103072, 0.200137, -0.099511]\n",
      "2 回目学習\n",
      "予測値 = 1.0099\n",
      "重みリスト = [0.102129, 0.200057, -0.099640]\n",
      "3 回目学習\n",
      "予測値 = 1.0007\n",
      "重みリスト = [0.102059, 0.200051, -0.099650]\n",
      "\n",
      "シーズン　第3試合\n",
      "1 回目学習\n",
      "予測値 = 1.1206\n",
      "重みリスト = [0.090120, 0.199086, -0.100253]\n",
      "2 回目学習\n",
      "予測値 = 1.0013\n",
      "重みリスト = [0.089988, 0.199076, -0.100260]\n",
      "3 回目学習\n",
      "予測値 = 1.0000\n",
      "重みリスト = [0.089987, 0.199076, -0.100260]\n",
      "\n",
      "シーズン　第4試合\n",
      "1 回目学習\n",
      "予測値 = 0.8888\n",
      "重みリスト = [0.099996, 0.200077, -0.099147]\n",
      "2 回目学習\n",
      "予測値 = 0.9809\n",
      "重みリスト = [0.101716, 0.200249, -0.098956]\n",
      "3 回目学習\n",
      "予測値 = 0.9967\n",
      "重みリスト = [0.102012, 0.200278, -0.098923]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 予測する関数 neural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    # 予測値を初期化\n",
    "    out = 0\n",
    "    # 入力層ニューロンの数分繰り返す\n",
    "    for i in range(len(input)):\n",
    "        # 予測値（＝加重和＝内積値）を求める\n",
    "        out += (input[i] * weights[i])\n",
    "    # 予測値を返す\n",
    "    return out\n",
    "\n",
    "# スカラー積を求める関数 ele_mul の定義\n",
    "def ele_mul(scalar, vector):\n",
    "    # スカラー積の結果を返すリストの初期化\n",
    "    out = [0, 0, 0]\n",
    "    # ベクトルの長さ分繰り返す\n",
    "    for i in range(len(out)):\n",
    "        # スカラー積を求めて、リストに追加する\n",
    "        out[i] = vector[i] * scalar\n",
    "    # スカラー積を返す\n",
    "    return out\n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値リスト\n",
    "    truth：目的値\n",
    "    pred：予測値\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "def grad_descent_learn(input, truth, pred, weights, alpha):\n",
    "    # 誤差を求める\n",
    "    pass\n",
    "    # デルタを求める\n",
    "    \n",
    "    # 重みの微調整量を求める\n",
    "    \n",
    "    # 重みを修正する\n",
    "    \n",
    "    \n",
    "    # 更新した重みリストを返す\n",
    "    \n",
    "\n",
    "# 学習結果を表示する関数 disp_learn の定義\n",
    "'''\n",
    "関数名：disp_learn\n",
    "引数：iter = 学習回数、pred = 予測値、weights = 重みリスト\n",
    "処理：学習回数、予測値（小数点以下４桁）、重みを表示する（小数点以下６桁）\n",
    "戻り値：なし\n",
    "'''\n",
    "def disp_learn(iter, pred, weights):\n",
    "    # 学習回数を表示\n",
    "    pass\n",
    "    # 予測値を表示\n",
    "    \n",
    "    # 重みリストを表示\n",
    "    \n",
    "    \n",
    "        \n",
    "            \n",
    "        \n",
    "            \n",
    "    \n",
    "\n",
    "# 入力データセット\n",
    "# シーズンの各選手の足指の平均数を初期化\n",
    "toes =  [8.5, 9.5, 9.9, 9.0]\n",
    "# シーズンの勝率を初期化\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "# シーズンのファンの数（百万単位）を初期化\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "# シーズン４試合の勝ち負けを初期化\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "# シーズン第１試合の結果初期化\n",
    "truth = win_or_lose_binary[0]\n",
    "\n",
    "# アルファを初期化\n",
    "alpha = 0.01\n",
    "# 入力層から出力層への重みの初期化\n",
    "weights = [0.1, 0.2, -0.1]\n",
    "\n",
    "# シーズン全試合（４試合）を学習する\n",
    "for i in range(4):\n",
    "    # 第何回目の試合なのか表示\n",
    "    print(\"シーズン　第\" + str(i+1) + \"試合\")\n",
    "    # 入力データをセット\n",
    "    input = [toes[i], wlrec[i], nfans[i]]\n",
    "    # ３回学習する\n",
    "    for j in range(3):\n",
    "        # 予測する\n",
    "        pred = neural_network(input, weights)\n",
    "        # 学習＝重みを修正\n",
    "        \n",
    "        # 学習結果を表示\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "シーズン　第1試合\n1回目学習\n予測値 = 0.8600000000000001\n重みリスト[0.1119, 0.20091, -0.09832]\n2回目学習\n予測値 = 0.9637574999999999\n重みリスト[0.11498061250000001, 0.20114557625, -0.09788509000000001]\n3回目学習\n予測値 = 0.9906177228125002\n重みリスト[0.1157781060609375, 0.20120656105171877, -0.09777250267375001]\nシーズン　第2試合\n1回目学習\n予測値 = 1.1337530029444063\n重みリスト[0.1030715707812189, 0.20013653702816353, -0.0995112917120273]\n2回目学習\n予測値 = 1.0099244728184749\n重みリスト[0.10212874586346378, 0.20005714124561574, -0.09964030985866747]\n3回目学習\n予測値 = 1.000736395883131\n重みリスト[0.10205878825456634, 0.2000512500785507, -0.09964988300514817]\nシーズン　第3試合\n1回目学習\n予測値 = 1.1205980622804732\n重みリスト[0.09011958008879949, 0.19908646558030693, -0.10025287331655053]\n2回目学習\n予測値 = 1.0013265786850851\n重みリスト[0.08998824879897606, 0.19907585295082625, -0.10025950620997595]\n3回目学習\n予測値 = 1.000014592365536\n重みリスト[0.089986804154788, 0.19907573621190197, -0.10025957917180363]\nシーズン　第4試合\n1回目学習\n予測値 = 0.8887898208120002\n重みリスト[0.09999572028170799, 0.20007662782459398, -0.09914747737992363]\n2回目学習\n予測値 = 0.9808829701975827\n重みリスト[0.10171625296392554, 0.20024868109281574, -0.09895630708189945]\n3回目学習\n予測値 = 0.9967137825769645\n重みリスト[0.10201201253199874, 0.20027825704962307, -0.09892344490766909]\n"
     ]
    }
   ],
   "source": [
    "# 予測する関数 neural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    # 予測値を初期化\n",
    "    out = 0\n",
    "    # 入力層ニューロンの数分繰り返す\n",
    "    for i in range(len(input)):\n",
    "        # 予測値（＝加重和＝内積値）を求める\n",
    "        out += (input[i] * weights[i])\n",
    "    # 予測値を返す\n",
    "    return out\n",
    "\n",
    "# スカラー積を求める関数 ele_mul の定義\n",
    "def ele_mul(scalar, vector):\n",
    "    # スカラー積の結果を返すリストの初期化\n",
    "    out = [0, 0, 0]\n",
    "    # ベクトルの長さ分繰り返す\n",
    "    for i in range(len(out)):\n",
    "        # スカラー積を求めて、リストに追加する\n",
    "        out[i] = vector[i] * scalar\n",
    "    # スカラー積を返す\n",
    "    return out\n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値リスト\n",
    "    truth：目的値\n",
    "    pred：予測値\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "def grad_descent_learn(input, truth, pred, weights, alpha):\n",
    "    # 誤差を求める\n",
    "    error = (pred - truth) ** 2\n",
    "    # デルタを求める\n",
    "    delta = pred - truth\n",
    "    # 重みの微調整量を求める\n",
    "    weights_deltas = ele_mul(delta, input)\n",
    "    # 重みを修正する\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weights_deltas[i]\n",
    "    # 更新した重みリストを返す\n",
    "    return weights\n",
    "\n",
    "# 学習結果を表示する関数 disp_learn の定義\n",
    "'''\n",
    "関数名：disp_learn\n",
    "引数：iter = 学習回数、pred = 予測値、weights = 重みリスト\n",
    "処理：学習回数、予測値（小数点以下４桁）、重みを表示する（小数点以下６桁）\n",
    "戻り値：なし\n",
    "'''\n",
    "def disp_learn(iter, pred, weights):\n",
    "    # 学習回数を表示\n",
    "    print(str(iter+1) + \"回目学習\")\n",
    "    # 予測値を表示\n",
    "    print(\"予測値 = \" + str(pred))\n",
    "    # 重みリストを表示\n",
    "    print(\"重みリスト\" + str(weights))\n",
    "    \n",
    "\n",
    "# 入力データセット\n",
    "# シーズンの各選手の足指の平均数を初期化\n",
    "toes =  [8.5, 9.5, 9.9, 9.0]\n",
    "# シーズンの勝率を初期化\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "# シーズンのファンの数（百万単位）を初期化\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "# シーズン４試合の勝ち負けを初期化\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "# シーズン第１試合の結果初期化\n",
    "truth = win_or_lose_binary[0]\n",
    "\n",
    "# アルファを初期化\n",
    "alpha = 0.01\n",
    "# 入力層から出力層への重みの初期化\n",
    "weights = [0.1, 0.2, -0.1]\n",
    "\n",
    "# シーズン全試合（４試合）を学習する\n",
    "for i in range(4):\n",
    "    # 第何回目の試合なのか表示\n",
    "    print(\"シーズン　第\" + str(i+1) + \"試合\")\n",
    "    # 入力データをセット\n",
    "    input = [toes[i], wlrec[i], nfans[i]]\n",
    "    # ３回学習する\n",
    "    for iter in range(3):\n",
    "        # 予測する\n",
    "        pred = neural_network(input, weights)\n",
    "        # 学習＝重みを修正\n",
    "        weights = grad_descent_learn(input, truth, pred, weights, alpha)\n",
    "        # 学習結果を表示\n",
    "        disp_learn(iter, pred, weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題３\n",
    "### ▶ 下図のニューラルネットワークの実装を、未完成プログラムのコメントと実行結果をもとに行ってください。\n",
    "### 注意）アルファの値を自分で考えて設定してください。\n",
    "![](chap5_ex_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 回目学習\n",
      "予測値 = -12.1870\n",
      "重みリスト = [0.102413, -0.113230, 0.111209, -0.096044, 0.201582]\n",
      "2 回目学習\n",
      "予測値 = -6.3640\n",
      "重みリスト = [0.103761, -0.064774, 0.117468, -0.093835, 0.202466]\n",
      "3 回目学習\n",
      "予測値 = -3.1123\n",
      "重みリスト = [0.104513, -0.037715, 0.120964, -0.092601, 0.202960]\n",
      "4 回目学習\n",
      "予測値 = -1.2965\n",
      "重みリスト = [0.104934, -0.022604, 0.122916, -0.091912, 0.203235]\n",
      "5 回目学習\n",
      "予測値 = -0.2824\n",
      "重みリスト = [0.105168, -0.014166, 0.124006, -0.091527, 0.203389]\n",
      "6 回目学習\n",
      "予測値 = 0.2839\n",
      "重みリスト = [0.105299, -0.009454, 0.124615, -0.091312, 0.203475]\n",
      "7 回目学習\n",
      "予測値 = 0.6001\n",
      "重みリスト = [0.105373, -0.006823, 0.124955, -0.091193, 0.203523]\n",
      "8 回目学習\n",
      "予測値 = 0.7767\n",
      "重みリスト = [0.105413, -0.005353, 0.125144, -0.091126, 0.203550]\n",
      "9 回目学習\n",
      "予測値 = 0.8753\n",
      "重みリスト = [0.105436, -0.004532, 0.125250, -0.091088, 0.203565]\n",
      "10 回目学習\n",
      "予測値 = 0.9304\n",
      "重みリスト = [0.105449, -0.004074, 0.125310, -0.091067, 0.203573]\n",
      "11 回目学習\n",
      "予測値 = 0.9611\n",
      "重みリスト = [0.105456, -0.003818, 0.125343, -0.091056, 0.203578]\n",
      "12 回目学習\n",
      "予測値 = 0.9783\n",
      "重みリスト = [0.105460, -0.003675, 0.125361, -0.091049, 0.203580]\n",
      "13 回目学習\n",
      "予測値 = 0.9879\n",
      "重みリスト = [0.105462, -0.003596, 0.125371, -0.091045, 0.203582]\n",
      "14 回目学習\n",
      "予測値 = 0.9932\n",
      "重みリスト = [0.105464, -0.003551, 0.125377, -0.091043, 0.203583]\n",
      "15 回目学習\n",
      "予測値 = 0.9962\n",
      "重みリスト = [0.105464, -0.003526, 0.125380, -0.091042, 0.203583]\n",
      "16 回目学習\n",
      "予測値 = 0.9979\n",
      "重みリスト = [0.105465, -0.003512, 0.125382, -0.091042, 0.203583]\n",
      "17 回目学習\n",
      "予測値 = 0.9988\n",
      "重みリスト = [0.105465, -0.003504, 0.125383, -0.091041, 0.203584]\n",
      "18 回目学習\n",
      "予測値 = 0.9993\n",
      "重みリスト = [0.105465, -0.003500, 0.125384, -0.091041, 0.203584]\n",
      "19 回目学習\n",
      "予測値 = 0.9996\n",
      "重みリスト = [0.105465, -0.003498, 0.125384, -0.091041, 0.203584]\n",
      "20 回目学習\n",
      "予測値 = 0.9998\n",
      "重みリスト = [0.105465, -0.003496, 0.125384, -0.091041, 0.203584]\n"
     ]
    }
   ],
   "source": [
    "# 予測する関数 neural_network の定義\n",
    "def neural_network():\n",
    "    # 予測値を初期化\n",
    "    pass\n",
    "    # 入力層ニューロンの数分繰り返す\n",
    "    \n",
    "        # 予測値（＝加重和＝内積値）を求める\n",
    "        \n",
    "    # 予測値を返す\n",
    "    \n",
    "\n",
    "# スカラー積を求める関数 ele_mul の定義\n",
    "def ele_mul():\n",
    "    # スカラー積の結果を返すリストの初期化\n",
    "    pass\n",
    "    # ベクトルの長さ分繰り返す\n",
    "   \n",
    "        # スカラー積を求めて、リストに追加する\n",
    "        \n",
    "    # スカラー積を返す\n",
    "    \n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値リスト\n",
    "    truth：目的値\n",
    "    pred：予測値\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "def grad_descent_learn(input, truth, pred, weights, alpha):\n",
    "    # 誤差を求める\n",
    "    pass\n",
    "    # デルタを求める\n",
    "    \n",
    "    # 重みの微調整量を求める\n",
    "    \n",
    "    # 重みを修正する\n",
    "    \n",
    "        \n",
    "    # 更新した重みリストを返す\n",
    "    \n",
    "\n",
    "# 学習結果を表示する関数 disp_learn の定義\n",
    "'''\n",
    "関数名：disp_learn\n",
    "引数：iter = 学習回数、pred = 予測値、weights = 重みリスト\n",
    "処理：学習回数、予測値（小数点以下４桁）、重みを表示する（小数点以下６桁）\n",
    "戻り値：なし\n",
    "'''\n",
    "def disp_learn(iter, pred, weights):\n",
    "    # 学習回数を表示\n",
    "    pass\n",
    "    # 予測値を表示\n",
    "    \n",
    "    # 重みリストを表示\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# アルファを初期化\n",
    "alpha = \n",
    "\n",
    "# 入力層の初期化\n",
    "#       [身長, 体重, 年収, 血液型, イケメン度]\n",
    "\n",
    "\n",
    "# 入力層から出力層への重みの初期化\n",
    "\n",
    "\n",
    "# 出力層の初期化\n",
    "\n",
    "\n",
    "# ２０回学習する\n",
    "\n",
    "    # 予測する\n",
    "    \n",
    "    # 学習＝重みを修正\n",
    "    \n",
    "    # 学習結果を表示\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題４\n",
    "### ▶ 下記のプログラムにおいて学習するタスクを関数化します。未完成リストのコメントに従ってプログラムを完成させてください。実行結果通りになるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👇リスト（参照）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:[0.293825, 0.25655, 0.868475]\n",
      "[けが度 = 0.195, 勝ち負け = 0.13, 悲しみ度 = 0.5850000000000001]\n"
     ]
    }
   ],
   "source": [
    "# チームの勝敗を予測するだけでなく、選手が喜んでいるのかどうかも予測する。\n",
    "# また、けがをしたチームメンバーの割合も予測する。この予測では、現在の勝敗記録のみを使用する。\n",
    "\n",
    "# 予測をする関数 neural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    pred = ele_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "# 加重和（内積）を計算する関数 ele_mul の定義\n",
    "def ele_mul(input, weights):\n",
    "    # 加重和リストの初期化\n",
    "    out = []\n",
    "    # 重みリストの長さ分繰り返す\n",
    "    for i in range(len(weights)):\n",
    "        # 加重和を求めて、加重和リストに追加する\n",
    "        out.append(input * weights[i])\n",
    "    # 加重和を返す\n",
    "    return out\n",
    "\n",
    "# スカラー積を求める関数 scalar_ele_mul の定義\n",
    "def scalar_ele_mul(number, vector):\n",
    "    # スカラー積を要素とするリストの初期化\n",
    "    output = []\n",
    "    # 引数 vector の長さ分繰り返す\n",
    "    for i in range(len(vector)):\n",
    "        # スカラー積を求めてリストに追加する\n",
    "        output.append(number * vector[i])\n",
    "    # スカラー積を要素とするリストを返す\n",
    "    return output\n",
    "\n",
    "# 重みの初期化：[勝敗からけが？への重み, 勝敗から勝った？への重み, 勝敗から悲しい？への重み]\n",
    "weights = [0.3, 0.2, 0.9]\n",
    "\n",
    "# １シーズン４試合の勝率の初期化\n",
    "wlrec = [0.65, 1.0, 1.0, 0.9]\n",
    "# １シーズン４試合のけがの初期化\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]\n",
    "# １シーズン４試合の勝ち負けの初期化\n",
    "win   = [  1,   1,   0,   1]\n",
    "# １シーズン４試合の悲しみ度の初期化\n",
    "sad   = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "# 入力値の初期化（シーズン第１試合の勝率）\n",
    "input = wlrec[0]\n",
    "# シーズン第１試合の事実\n",
    "# [第１試合のけが, 第１試合の勝ち負け, 第１試合の悲しみ度]\n",
    "truth = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "# 予測する\n",
    "pred = neural_network(input, weights)\n",
    "\n",
    "# デルタ（純誤差）リストの初期化\n",
    "# [けが, 勝ち負け, 悲しみ度]\n",
    "delta = []\n",
    "# 出力層のユニット数分繰り返す\n",
    "for i in range(len(truth)):\n",
    "    # 各ユニットごとの純誤差を求めて、純誤差リストに追加する\n",
    "    delta.append(pred[i] - truth[i])\n",
    "\n",
    "# 重み微調整量を求める\n",
    "weight_deltas = scalar_ele_mul(input, delta)\n",
    "# 重み微調整用アルファの初期化\n",
    "alpha = 0.1\n",
    "# 学習する\n",
    "for i in range(len(weights)):\n",
    "    # 重みを更新する\n",
    "    weights[i] -= (weight_deltas[i] * alpha)\n",
    "\n",
    "# 重みを表示\n",
    "print(\"Weights:\" + str(weights))\n",
    "\n",
    "# 予測値の表示\n",
    "print('[けが度 = {}, 勝ち負け = {}, 悲しみ度 = {}]'.format(pred[0], pred[1], pred[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👇未完成リスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weights:[0.293825, 0.25655, 0.868475]\n[けが度 = 0.195, 勝ち負け = 0.13, 悲しみ度 = 0.5850000000000001]\n"
     ]
    }
   ],
   "source": [
    "# チームの勝敗を予測するだけでなく、選手が喜んでいるのかどうかも予測する。\n",
    "# また、けがをしたチームメンバーの割合も予測する。この予測では、現在の勝敗記録のみを使用する。\n",
    "\n",
    "# 予測をする関数 neural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    pred = ele_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "# 加重和（内積）を計算する関数 ele_mul の定義\n",
    "def ele_mul(input, weights):\n",
    "    # 加重和リストの初期化\n",
    "    out = []\n",
    "    # 重みリストの長さ分繰り返す\n",
    "    for i in range(len(weights)):\n",
    "        # 加重和を求めて、加重和リストに追加する\n",
    "        out.append(input * weights[i])\n",
    "    # 加重和を返す\n",
    "    return out\n",
    "\n",
    "# スカラー積を求める関数 scalar_ele_mul の定義\n",
    "def scalar_ele_mul(number, vector):\n",
    "    # スカラー積を要素とするリストの初期化\n",
    "    output = []\n",
    "    # 引数 vector の長さ分繰り返す\n",
    "    for i in range(len(vector)):\n",
    "        # スカラー積を求める\n",
    "        output.append(number * vector[i])\n",
    "    # スカラー積を要素とするリストを返す\n",
    "    return output\n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値\n",
    "    truth：目的値リスト\n",
    "    pred：予測値リスト\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "\n",
    "def grad_descent_learn(input, truth, pred, weights, alpha):\n",
    "    # デルタの初期化\n",
    "    delta = []\n",
    "    # 誤差とデルタを求める\n",
    "    for i in range(len(truth)):\n",
    "        delta.append(pred[i] - truth[i])\n",
    "    weights_deltas = scalar_ele_mul(input, delta)\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weights_deltas[i]\n",
    "    return weights\n",
    "\n",
    "# １シーズン４試合の勝率の初期化\n",
    "wlrec = [0.65, 1.0, 1.0, 0.9]\n",
    "# １シーズン４試合のけがの初期化\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]\n",
    "# １シーズン４試合の勝ち負けの初期化\n",
    "win   = [  1,   1,   0,   1]\n",
    "# １シーズン４試合の悲しみ度の初期化\n",
    "sad   = [0.1, 0.0, 0.1, 0.2]\n",
    "# 重みの初期化：[勝敗からけが？への重み, 勝敗から勝った？への重み, 勝敗から悲しい？への重み]\n",
    "weights = [0.3, 0.2, 0.9] \n",
    "# 入力値の初期化（シーズン第１試合の勝率）\n",
    "input = wlrec[0]\n",
    "# シーズン第１試合の事実\n",
    "# [第１試合のけが, 第１試合の勝ち負け, 第１試合の悲しみ度]\n",
    "truth = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "# 予測する\n",
    "pred = neural_network(input, weights)\n",
    "# 重み微調整用アルファの初期化\n",
    "alpha = 0.1\n",
    "# 学習する\n",
    "weights = grad_descent_learn(input, truth, pred, weights, alpha)\n",
    "\n",
    "# 重みを表示\n",
    "print(\"Weights:\" + str(weights))\n",
    "\n",
    "# 予測値の表示\n",
    "print('[けが度 = {}, 勝ち負け = {}, 悲しみ度 = {}]'.format(pred[0], pred[1], pred[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('lecture-GAa8e1uk': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "interpreter": {
   "hash": "ab5071c795c90634bb65528267664959098047cb3b55eb9ef645391ba2ede91d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}