{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第６章　演習１\n",
    "### ▶ 下記のプログラムリストを未完成プログラムリストのコメントに従って実装してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👇プログラムリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力層 = \n",
      "[[1 0 1]\n",
      " [0 1 1]\n",
      " [0 0 1]\n",
      " [1 1 1]]\n",
      "目的値（出力層）= \n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "入力層と中間層間の重み = \n",
      "[[-0.16595599  0.44064899 -0.99977125]\n",
      " [-0.39533485 -0.70648822 -0.81532281]\n",
      " [-0.62747958 -0.30887855 -0.20646505]]\n",
      "中間層と出力層間の重み = \n",
      "[[ 0.07763347]\n",
      " [-0.16161097]\n",
      " [ 0.370439  ]]\n",
      "入力層 = [[1 0 1]]\n",
      "中間層 = [[-0.79343557  0.13177044 -1.2062363 ]]\n",
      "調整後の中間層 = [[-0.          0.13177044 -0.        ]]\n",
      "出力層 = [[-0.02129555]]\n",
      "更新後の中間層と出力層間の重み =\n",
      "[[ 0.07763347]\n",
      " [-0.13469566]\n",
      " [ 0.370439  ]]\n",
      "更新後の入力層と中間層間の重み =\n",
      "[[-0.16595599  0.40763847 -0.99977125]\n",
      " [-0.39533485 -0.70648822 -0.81532281]\n",
      " [-0.62747958 -0.34188906 -0.20646505]]\n"
     ]
    }
   ],
   "source": [
    "# numpy インポート　別名 np\n",
    "import numpy as np\n",
    "# 乱数のシード（種）を設定する\n",
    "# 同じパターンの乱数を生成する\n",
    "np.random.seed(1)\n",
    "\n",
    "# x が正なら x を、x が負なら 0 を返す関数 relu の定義\n",
    "def relu(x):\n",
    "  return (x > 0) * x\n",
    "\n",
    "# output が正なら 1 を、負なら 0 を返す関数 relu2derive 関数の定義\n",
    "def relu2deriv(output):\n",
    "  return output > 0 # returns 1 for input > 0\n",
    "                    # return 0 otherwise\n",
    "\n",
    "# 入力層（= 信号パターン）の初期化\n",
    "lights = np.array( [[ 1, 0, 1 ],\n",
    "                    [ 0, 1, 1 ],\n",
    "                    [ 0, 0, 1 ],\n",
    "                    [ 1, 1, 1 ] ] )\n",
    "# 入力層の表示\n",
    "print('入力層 = ')\n",
    "print(lights)\n",
    "# 目的値（出力層）の初期化、転置行列にする\n",
    "'''\n",
    "[[1, 1, 0, 0]].T\n",
    "    ⇓\n",
    "[ [1],\n",
    "  [1],\n",
    "  [0],\n",
    "  [0] ]\n",
    "'''\n",
    "walk_stop = np.array([[ 1, 1, 0, 0]]).T\n",
    "# 目的値（出力層）を表示\n",
    "print('目的値（出力層）= ')\n",
    "print(walk_stop)\n",
    "# アルファの初期化\n",
    "alpha = 0.2\n",
    "# 中間層のユニット数（= ノード数）\n",
    "hidden_size = 3\n",
    "# ３行３列の乱数を生成して weights_0_1（= 入力層と中間層間の重み）に設定\n",
    "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
    "# ３行１列の乱数を生成して weights_1_2（= 中間層と出力層間の重み）に設定\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "# 入力層と中間層間の重みの表示\n",
    "print('入力層と中間層間の重み = ')\n",
    "print(weights_0_1)\n",
    "# 中間層と出力層間の重みの表示\n",
    "print('中間層と出力層間の重み = ')\n",
    "print(weights_1_2)\n",
    "\n",
    "# 入力層に値を設定（信号パターン１）\n",
    "layer_0 = lights[0:1]\n",
    "# 入力層を表示\n",
    "print('入力層 = {}'.format(layer_0))\n",
    "# 入力層の予測を求めて、中間層に設定\n",
    "layer_1 = np.dot(layer_0, weights_0_1)\n",
    "# 中間層を表示\n",
    "print('中間層 = {}'.format(layer_1))\n",
    "# 中間層の値において、負の値は０にする\n",
    "layer_1 = relu(layer_1)\n",
    "# 再度中間層を表示\n",
    "print('調整後の中間層 = {}'.format(layer_1))\n",
    "# 中間層の予測を求めて、出力層に設定\n",
    "layer_2 = np.dot(layer_1, weights_1_2)\n",
    "# 出力層を表示\n",
    "print('出力層 = {}'.format(layer_2))\n",
    "# 中間層と出力層間のデルタを求める\n",
    "layer_2_delta = (layer_2 - walk_stop[0:1])\n",
    "\n",
    "# layer_2 から layer_1 へ逆伝播\n",
    "# layer_2 のデルタをもとに layer_1 のデルタを求める\n",
    "layer_1_delta = layer_2_delta.dot(weights_1_2.T)\n",
    "# layer_1_delta を修正（負の値は０にする）\n",
    "layer_1_delta *= relu2deriv(layer_1)\n",
    "\n",
    "# 出力層のデルタ layer_2_delta を使用して、\n",
    "# 中間層と出力層間の重み微調整量 weight_delta_1_2 を求める\n",
    "weight_delta_1_2 = layer_1.T.dot(layer_2_delta)\n",
    "# 中間層のデルタ layer_1_delta を使用して、\n",
    "# 入力層と中間層間の重みの微調整量 weight_delta_0_1 を求める\n",
    "weight_delta_0_1 = layer_0.T.dot(layer_1_delta)\n",
    "# 中間層と出力層間の重みを更新する\n",
    "weights_1_2 -= alpha * weight_delta_1_2\n",
    "# 入力層と中間層間の重みを更新する\n",
    "weights_0_1 -= alpha * weight_delta_0_1\n",
    "# 更新後の中間層と出力層間の重みを表示\n",
    "print('更新後の中間層と出力層間の重み =')\n",
    "print(weights_1_2)\n",
    "# 更新後の入力層と中間層間の重みを表示\n",
    "print('更新後の入力層と中間層間の重み =')\n",
    "print(weights_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👇未完成プログラムリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力層 = \n",
      "[[1 0 1]\n",
      " [0 1 1]\n",
      " [0 0 1]\n",
      " [1 1 1]]\n",
      "目的値（出力層）= \n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "入力層と中間層間の重み = \n",
      "[[-0.16595599  0.44064899 -0.99977125]\n",
      " [-0.39533485 -0.70648822 -0.81532281]\n",
      " [-0.62747958 -0.30887855 -0.20646505]]\n",
      "中間層と出力層間の重み = \n",
      "[[ 0.07763347]\n",
      " [-0.16161097]\n",
      " [ 0.370439  ]]\n",
      "入力層 = [[1 0 1]]\n",
      "中間層 = [[-0.79343557  0.13177044 -1.2062363 ]]\n",
      "調整後の中間層 = [[-0.          0.13177044 -0.        ]]\n",
      "出力層 = [[-0.02129555]]\n",
      "更新後の中間層と出力層間の重み = \n",
      "[[ 0.07763347]\n",
      " [-0.13469566]\n",
      " [ 0.370439  ]]\n",
      "更新後の入力層と中間層間の重み = \n",
      "[[-0.16595599  0.40763847 -0.99977125]\n",
      " [-0.39533485 -0.70648822 -0.81532281]\n",
      " [-0.62747958 -0.34188906 -0.20646505]]\n"
     ]
    }
   ],
   "source": [
    "# numpy インポート　別名 np\n",
    "import numpy as np\n",
    "# 乱数のシード（種）を設定する\n",
    "# 同じパターンの乱数を生成する\n",
    "np.random.seed(1)\n",
    "\n",
    "# x が正なら x を、x が負なら 0 を返す関数 relu の定義\n",
    "def relu(x):\n",
    "  return (x > 0) * x\n",
    "\n",
    "# output が正なら 1 を、負なら 0 を返す関数 relu2derive 関数の定義\n",
    "def relu2deriv(output):\n",
    "  return output > 0 # returns 1 for input > 0\n",
    "                    # return 0 otherwise\n",
    "\n",
    "# 予測を行う関数 neural_network(input, weight) の定義\n",
    "'''\n",
    "関数名：neural_network\n",
    "引数：input = 入力データセットリスト、weight = 重み行列\n",
    "処理：input と weight の加重和を計算する\n",
    "戻り値：加重和リスト\n",
    "'''\n",
    "\n",
    "  # numpy の dot メソッドを使用して、input と weight の加重和を計算する\n",
    "  pred = \n",
    "  # 加重和を返す\n",
    "  \n",
    "\n",
    "# 乱数発生により重み行列を生成する関数 create_weight(layer_1_num, layer_2_num) の定義\n",
    "'''\n",
    "関数名：create_weight\n",
    "引数：layer_1_num = 層１の長さ、layer_2_num = 層２の長さ\n",
    "処理：乱数を発生させて、layer_1_num 行、layer_2_num 列の行列に重みを設定する\n",
    "戻り値：重み行列\n",
    "'''\n",
    "\n",
    "  # layer_1 の要素数の行、layer_2 の要素数の列の行列に、乱数発生による重みを設定\n",
    "  weight_1_2 = \n",
    "  # 重み行列を返す\n",
    "  \n",
    "\n",
    "# 誤差逆伝播法による学習関数 \n",
    "# back_propagation(input, hidden, output, goal, weight_i_h, weight_h_o) の定義\n",
    "'''\n",
    "関数名：back_propagation\n",
    "引数：\n",
    "  input = 入力層のデータセットリスト\n",
    "  hidden = 中間層の予測値リスト\n",
    "  output = 出力層の予測値リスト\n",
    "  goal = 目的値行列\n",
    "  weight_i_h = 入力層と中間層間の重み行列\n",
    "  weight_h_o = 中間層と出力層間の重み行列\n",
    "  input_num = 入力層に与えられるパターン番号\n",
    "処理：誤差逆伝播法により学習する\n",
    "戻り値：\n",
    "  更新した入力層と中間層の重み行列と、更新した中間層と出力層間の重み行列\n",
    "'''\n",
    "\n",
    "  # 出力層のデルタを計算する\n",
    "  output_delta = \n",
    "  # 出力層のデルタを使用して中間層のデルタを計算する（逆伝播）\n",
    "  hidden_delta = \n",
    "  # 中間層のデルタを修正\n",
    "  hidden_delta *= relu2deriv(hidden)\n",
    "  # 中間層と出力層間の重みの微調整量を計算\n",
    "  weight_delta_h_o = \n",
    "  # 入力層と中間層間の重みの微調整量を計算\n",
    "  weight_delta_i_h = \n",
    "  # 中間層と出力層間の重みを更新する\n",
    "  \n",
    "  # 入力層と中間層間の重みを更新する\n",
    "  \n",
    "  # 更新した入力層と中間層間の重みと、更新した中間層と出力層間の重みを返す\n",
    "  return weight_i_h, weight_h_o\n",
    "\n",
    "# 入力層（= 信号パターン）の初期化\n",
    "lights = np.array( [[ 1, 0, 1 ],\n",
    "                    [ 0, 1, 1 ],\n",
    "                    [ 0, 0, 1 ],\n",
    "                    [ 1, 1, 1 ] ] )\n",
    "# 入力層の表示\n",
    "print('入力層 = ')\n",
    "print(lights)\n",
    "# 目的値（出力層）の初期化、転置行列にする\n",
    "'''\n",
    "[[1, 1, 0, 0]].T\n",
    "    ⇓\n",
    "[ [1],\n",
    "  [1],\n",
    "  [0],\n",
    "  [0] ]\n",
    "'''\n",
    "walk_stop = np.array([[ 1, 1, 0, 0]]).T\n",
    "# 目的値（出力層）を表示\n",
    "print('目的値（出力層）= ')\n",
    "print(walk_stop)\n",
    "# アルファの初期化\n",
    "alpha = 0.2\n",
    "# 中間層のユニット数（= ノード数）\n",
    "hidden_size = 3\n",
    "# 乱数を生成して weights_i_h（= 入力層と中間層間の重み）に設定\n",
    "weight_i_h = \n",
    "# 乱数を生成して weights_h_o（= 中間層と出力層間の重み）に設定\n",
    "weight_h_o = \n",
    "# 入力層と中間層間の重みの表示\n",
    "print('入力層と中間層間の重み = ')\n",
    "print(weight_i_h)\n",
    "# 中間層と出力層間の重みの表示\n",
    "print('中間層と出力層間の重み = ')\n",
    "print(weight_h_o)\n",
    "\n",
    "# 入力層に値を設定（信号パターン１）\n",
    "layer_0 = lights[0:1]\n",
    "# 入力層を表示\n",
    "print('入力層 = {}'.format(layer_0))\n",
    "# 入力層の予測を求めて、中間層に設定\n",
    "layer_1 = \n",
    "# 中間層を表示\n",
    "print('中間層 = {}'.format(layer_1))\n",
    "# 中間層の値において、負の値は０にする\n",
    "layer_1 = relu(layer_1)\n",
    "# 再度中間層を表示\n",
    "print('調整後の中間層 = {}'.format(layer_1))\n",
    "# 中間層の予測を求めて、出力層に設定\n",
    "layer_2 = \n",
    "# 出力層を表示\n",
    "print('出力層 = {}'.format(layer_2))\n",
    "\n",
    "# 誤差逆伝播法で学習する\n",
    "\n",
    "# 更新後の中間層と出力層間の重みを表示\n",
    "print('更新後の中間層と出力層間の重み = ')\n",
    "print(weight_h_o)\n",
    "# 更新後の入力層と中間層間の重みを表示\n",
    "print('更新後の入力層と中間層間の重み = ')\n",
    "print(weight_i_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
